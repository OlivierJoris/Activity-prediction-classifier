-- 1st attempt --
KNN with K=1 (knn_basic_1.py). Yield a Kaggle score of 0.52.

-- 2nd attempt --
KNN with K=25 (knn_basic_25.py). Yield a Kaggle score of 0.54.
Motivation: Theoretical - increasing the number of neighbors will the accuracy because we will not be dependent on a single value.

-- 3d attempt --
KNN with K=55 (knn_basic_55.py). Yield a Kaggle score of 0.53142.
Motivation: Yielded highest accuracy on LS with 10-fold cross validation and using negative log loss function as a scoring function.
There was an error in the implementation. So, this is the result of a mistake.

-- 4th attempt --
KNN with K=49 (knn_basic_49.py). Yield a Kaggle score of 0.52571.
Motivation: Yielded highest accuracy on LS with 10-fold cross validation and using negative log loss function as a scoring function.

