{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98ab0f10-879b-42f3-98cd-78f4500dc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random \n",
    "import pandas as pd\n",
    "\n",
    "from sktime.datatypes._panel._convert import from_3d_numpy_to_nested\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sktime.classification.compose import ColumnEnsembleClassifier\n",
    "from sktime.datasets import load_arrow_head\n",
    "from sktime.classification.interval_based import TimeSeriesForestClassifier\n",
    "from sktime.transformations.panel.compose import ColumnConcatenator\n",
    "from sktime.classification.shapelet_based import MrSEQLClassifier\n",
    "from sktime.datasets import load_basic_motions\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f64a33-bf79-4a9f-b50c-73d51c473cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TA CODE\n",
    "def load_data(data_path):\n",
    "    \n",
    "    FEATURES = range(2, 33)\n",
    "    N_TIME_SERIES = 3500\n",
    "\n",
    "    # Create the training and testing samples\n",
    "    LS_path = os.path.join(data_path, 'LS')\n",
    "    TS_path = os.path.join(data_path, 'TS')\n",
    "    X_train, X_test = [np.zeros((N_TIME_SERIES, len(FEATURES), 512)) for i in range(2)]\n",
    "    \n",
    "    for f in FEATURES:\n",
    "        data = np.loadtxt(os.path.join(LS_path, 'LS_sensor_{}.txt'.format(f)))\n",
    "        for i in range(N_TIME_SERIES):\n",
    "            X_train[i][f-2][:] = data[i]\n",
    "        data = np.loadtxt(os.path.join(TS_path, 'TS_sensor_{}.txt'.format(f)))\n",
    "        for i in range(N_TIME_SERIES):\n",
    "            X_test[i][f-2][:] = data[i]\n",
    "            \n",
    "    y_train = np.loadtxt(os.path.join(LS_path, 'activity_Id.txt'))\n",
    "       \n",
    "    return X_train, y_train, X_test\n",
    "\n",
    "def write_submission(y, where, submission_name='toy_submission.csv'):\n",
    "    os.makedirs(where, exist_ok=True)\n",
    "\n",
    "    SUBMISSION_PATH = os.path.join(where, submission_name)\n",
    "    if os.path.exists(SUBMISSION_PATH):\n",
    "        os.remove(SUBMISSION_PATH)\n",
    "\n",
    "    y = y.astype(int)\n",
    "    outputs = np.unique(y)\n",
    "\n",
    "    # Verify conditions on the predictions\n",
    "    if np.max(outputs) > 14:\n",
    "        raise ValueError('Class {} does not exist.'.format(np.max(outputs)))\n",
    "    if np.min(outputs) < 1:\n",
    "        raise ValueError('Class {} does not exist.'.format(np.min(outputs)))\n",
    "    \n",
    "    # Write submission file\n",
    "    with open(SUBMISSION_PATH, 'a') as file:\n",
    "        n_samples = len(y)\n",
    "        if n_samples != 3500:\n",
    "            raise ValueError('Check the number of predicted values.')\n",
    "\n",
    "        file.write('Id,Prediction\\n')\n",
    "\n",
    "        for n, i in enumerate(y):\n",
    "            file.write('{},{}\\n'.format(n+1, int(i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77871a2-51e6-4f48-ac9a-ee19f953b416",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # Directory containing the data folders\n",
    "    DATA_PATH = 'data'\n",
    "    X_train, y_train, X_test = load_data(DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1b960d9-6d1b-471c-9d22-fabc91076d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3500, 31)\n"
     ]
    }
   ],
   "source": [
    "    # Replace missing values\n",
    "    X_train = from_3d_numpy_to_nested(X_train)\n",
    "    X_test = from_3d_numpy_to_nested(X_test)\n",
    "    print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e6431-abb8-42b6-a046-419ebf2cc4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # clf = TimeSeriesForestClassifier(n_jobs = -1, random_state = 0).fit(X_train, y_train)\n",
    "    # X, y = load_arrow_head(return_X_y=True)\n",
    "    # print(X)\n",
    "    steps = [\n",
    "    (\"concatenate\", ColumnConcatenator()),\n",
    "    (\"classify\", TimeSeriesForestClassifier(n_estimators=100, n_jobs = -1)),\n",
    "    ]\n",
    "    \n",
    "    clf = Pipeline(steps)\n",
    "    clf.fit(X_train, y_train)\n",
    "    clf.score(X_test, y_test)\n",
    "#     LS_path = os.path.join(DATA_PATH, 'LS')   \n",
    "#     LS_subject_id = np.loadtxt(os.path.join(LS_path, 'subject_Id.txt'))\n",
    "    \n",
    "#     ids = [1, 2, 3, 4, 5]\n",
    "#     learning_id = [0, 0, 0]   \n",
    "#     scores = np.zeros(10)\n",
    "    \n",
    "#     random.seed()\n",
    "    \n",
    "#     for j in range(10):\n",
    "#         random.shuffle(ids)\n",
    "        \n",
    "#         for i in range(3):\n",
    "#             learning_id[i] = ids[i]\n",
    "            \n",
    "#         unique_ls, count_ls = np.unique(LS_subject_id, return_counts = True)\n",
    "        \n",
    "#         count = np.asarray((unique_ls, count_ls))\n",
    "        \n",
    "#         training_size = int(count[1][learning_id[0] - 1] + count[1][learning_id[1] - 1] + count[1][learning_id[2] - 1])\n",
    "        \n",
    "#         X_train_split = np.zeros((training_size, 31))\n",
    "#         X_test_split = np.zeros((3500 - training_size, 31))\n",
    "\n",
    "#         y_train_split = np.zeros((training_size, 1))\n",
    "#         y_test_split = np.zeros((3500 - training_size, 1))\n",
    "\n",
    "#         training_current_size, testing_current_size = 0, 0\n",
    "\n",
    "#         for i in range(3500):\n",
    "#             if LS_subject_id[i] in learning_id:\n",
    "#                 X_train_split[training_current_size] = X_train[i]\n",
    "#                 y_train_split[training_current_size] = y_train[i]\n",
    "#                 training_current_size += 1\n",
    "#             else:\n",
    "#                 X_test_split[testing_current_size] = X_train[i]\n",
    "#                 y_test_split[testing_current_size] = y_train[i]\n",
    "#                 testing_current_size += 1\n",
    "                \n",
    "#         clf = TimeSeriesForestClassifier(n_jobs = -1, random_state = 0).fit(X_train_split, y_train_split)\n",
    "#         y_pred = clf.predict(X_test_split)\n",
    "#         scores[i] = accuracy_score(y_test_split, y_pred)\n",
    "    \n",
    "#     print(np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c4af13f7-8287-498b-915e-a87d4798c746",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/olivierjoris/miniconda3/envs/ELEN0062/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:619: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-de1356140f40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mwrite_submission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'submissions'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ELEN0062/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1035\u001b[0m         \"\"\"\n\u001b[1;32m   1036\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_pass_fast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ELEN0062/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_forward_pass_fast\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0mhidden_activation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mACTIVATIONS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m             \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoefs_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m             \u001b[0mactivation\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercepts_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_layers_\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ELEN0062/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/ELEN0062/lib/python3.9/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    150\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "    clf.fit(X_train, y_train)\n",
    "    y_test = clf.predict(X_test)\n",
    "    write_submission(y_test, 'submissions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f5588-918a-48f5-bf7d-949da9b0c195",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
